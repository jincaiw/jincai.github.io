- 定义

  - Gartner-“大数据”是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应海量、高增长率和多样化的信息资产。

  - 麦肯锡全球研究所给出的定义是：一种规模大到在获取、存储、管理、分析方面大大超出了传统数据库软件工具能力范围的数据集合，具有海量的数据规模、快速的数据流转、多样的数据类型和价值密度低四大特征。

  - 1TU Y.3600标准首先明确给出了大数据的定义：一种允许可能在实时性约束条件下收集、存储、管理、分析和可视化具有异构特征的大量数据集的模式。

  - 国内普遍接受的定义：具有数量巨大、来源多样、生成极快、且多变等特征，。。。。

- 大数据的数据特征，有4V、5V、7V或11V特征等来描述

  - 容量（Volume）：数据的大小决定所考虑的数据的价值和潜在的信息（量）；

  - 速度（Velocity）：指获得数据的速度，实时获取需要的信息（速）：

  - 种类（Variety）：结构化数据、半结构化数据和非结构化数据（类）；

  - 价值（value）：价值密度低；合理运用大数据，以低成本创造高价值（价）；

  - 真实性（Veracity）：数据的质量，数据清洗，去伪存真（真）；

  - 上述定义都有一定的道理，特别是5V定义，目前已经被越来越多地接受。大数据时代最大的转变，就是放弃对因果关系的渴求，取而代之关注相关关系。也就是说，只要知道“是什么”，而不需要知道“为什么”

- 布局

  - 信息价值链（水平轴）

  - IT价值链（垂直轴）

- 预留。。。

  - 系统协调

  - 数据提供者

  - 大数据应用提供者

  - 数据消费者

  - 管理

- 数据收集

  - 大数据时代，数据的来源及其广泛，数据有不同的类型和格式，同时呈现爆发性增长的态势，这些特性对数据收集技术也提出了更高的要求。数据收集需要从不同的数据源实时的或及时的收集不同类型的数据并发送给存储系统或数据中间件系统进行后续处理。

  - 数据收集数据收集一般可分为设备数据收集和Web数据爬取两类，常常用的数据收集软件有Sqoop、Flume、Logstash、Kettle以及各种网络防爬虫Scrapy等

- 数据清洗

  - 数据预处理的引入，将有助于提升数据质量，并使得后继数据处理、分析、可视化过程更加容易、有效，有利于获得更好的用户体验。

  - 数据预处理形式上包括数据清理、数据集成、数据归约与数据转换等阶段

  - 数据清理技术包括数据不一致性检测技术、脏数据识别技术、数据过滤技术、数据修正技术、数据噪声的识别与平滑技术等：

  - 数据集成把来自多个数据源的数据进行集成，缩短数据之间的物理距离，形成一个集中统一的（同构/异构）数据库、数据立方体、数据宽表与文件等，

  - ＞数据归约技术可以在不损害挖掘结果准确性的前提下，降低数据集的规模，得到简化的数据集。归约策略与技术包括维归约技术、数值归约技术、数据抽样技术等。

  - ＞经过数据转换处理后，数据被变换或统一。数据转换不仅简化处理与分析过程、提升时效性，也使得分析挖掘的模式更容易被理解。数据转换处理技术包括基于规则或元数据的转换技术、基于模型和学习的转换技术等。

- 数据存储

- 